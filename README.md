

# ğŸš€ **Machine Learning **

*A collection of three end-to-end Machine Learning projects focusing on attrition prediction, pipeline debugging, and productivity optimization.*

This repository contains **three full ML workflows**, each designed to demonstrate practical, industry-level skills:

* ğŸ§  **Assignment 1 â€” Employee Attrition Prediction**
* ğŸ” **Assignment 2 â€” ML Pipeline Debugging & Data Leakage Detection**
* âš™ï¸ **Assignment 3 â€” Productivity Feature Engineering & Optimization**

Every assignment includes:

* A complete Jupyter Notebook
* Cleaned & processed dataset
* Baseline & optimized models
* Saved artifacts
* Documentation & visualizations

---

# ğŸ“ **Repository Structure**

```
/
â”œâ”€â”€ Assignment1/
â”‚   â”œâ”€â”€ train.ipynb
â”‚   â”œâ”€â”€ streamlit_app.py
â”‚   â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ DOCUMENTATION.md
â”‚
â”œâ”€â”€ Assignment2/
â”‚   â”œâ”€â”€ debug_broken_notebook.ipynb
â”‚   â”œâ”€â”€ fixed_pipeline.ipynb
â”‚   â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ DOCUMENTATION.md
â”‚
â”œâ”€â”€ Assignment3/
â”‚   â”œâ”€â”€ productivity_feature_engineering.ipynb
â”‚   â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ DOCUMENTATION.md
â”‚
â”œâ”€â”€ README.md   â† (this file)
â””â”€â”€ requirements.txt
```

---

# ğŸ§­ **Assignment 1 â€” Employee Attrition Prediction**

### ğŸ¯ **Goal**

Build a machine-learning pipeline to predict **employee attrition** and identify the main drivers behind employee turnover.

### âœ”ï¸ **Key Features**

* Full EDA + data cleaning
* Encoding of categorical variables
* Train 2+ models (Logistic Regression, RandomForest, etc.)
* Metrics: Accuracy, Precision, Recall, F1, ROC-AUC
* SHAP explanations for interpretability
* Streamlit app for real-time prediction

### ğŸ“¦ **Artifacts**

* `attrition_pipeline.joblib`
* Feature importance plots
* Model comparison table

### ğŸ“ **Outputs**

* Probability of attrition for any employee
* Ranked list of attrition factors
* Documentation: **Assignment1/DOCUMENTATION.md**

---

# ğŸ” **Assignment 2 â€” ML Pipeline Debugging & Data Leakage Detection**

### ğŸ¯ **Goal**

Identify and fix a deliberately broken ML pipeline suffering from **data leakage**, **incorrect preprocessing**, and **invalid evaluation**.

### âŒ Issues Found In Broken Notebook

* Target copied into features
* Splitting after scaling (leakage)
* Cross-validation applied on the test set
* Meaningless feature engineering
* Missing imputations & no encoder separation

### âœ”ï¸ Fixes Applied

* Correct split BEFORE preprocessing
* Proper scaling inside a Pipeline
* Removal of leaking features
* Fixed cross-validation (CV on training set only)
* Added SHAP to compare leaking vs clean model
* Clean reusable ML pipeline created

### ğŸ“¦ **Artifacts**

* `fixed_pipeline.joblib`
* Comparison plot: leaking vs correct ROC-AUC
* Debugging report (Assignment2/DOCUMENTATION.md)

---

# âš™ï¸ **Assignment 3 â€” Productivity Feature Engineering & Optimization**

### ğŸ¯ **Goal**

Predict employee **productivity_score** using advanced feature engineering and model tuning.

### ğŸ”§ **Feature Engineering Performed**

From raw columns:

* `hours_per_day` â†’ Working hours daily
* `hours_week` â†’ Weekly estimate
* `projects_completed` â†’ Alias
* `tasks_per_hour` â†’ Efficiency
* `tasks_per_day` â†’ Output distribution
* `absence_ratio` â†’ Absenteeism
* `work_intensity` â†’ Normalized workload
* `efficiency_adjusted` â†’ Penalized productivity
* `tasks_x_hours` â†’ Interaction term
* `tasks_x_absences` â†’ Absence impact

Unsupervised features:

* `behavior_cluster` via KMeans
* `pca_1, pca_2, pca_3` via PCA

### ğŸ“Š **Models**

* Baseline: Linear Regression
* Optimized: RandomForest / XGBoost
* Hyperparameter tuning using RandomizedSearchCV
* SelectKBest for feature selection

### ğŸ“ˆ **Before â†’ After Comparison**


| Metric | Baseline      | Optimized (Tuned) | Improvement      |
| ------ | ------------- | ----------------- | ---------------- |
| MAE    | `14.6558`     | `15.7956`         | â†“ `15.4484`      |
| RMSE   | `17.2980`     | `19.9289	`        | â†“ `18.4308`      |
| RÂ²     | `-0.0071`     | `-0.3367`         | â†“ `-0.1433`      |



### ğŸ“¦ **Artifacts**

* `best_pipeline.joblib`
* `final_features.joblib`
* `metrics_comparison.joblib`
* Feature-importance dashboard

### ğŸ“˜ Documentation

See: **Assignment3/DOCUMENTATION.md**

---

# ğŸ”§ **Installation Instructions**

```
git clone https://github.com/tigerhooduday/MLtrainingandDebug
cd project/
python -m venv .venv
source .venv/bin/activate   # (Windows: .\.venv\Scripts\activate)
pip install -r requirements.txt
```

---

# â–¶ï¸ **How to Run**

### **Assignment 1**

```
cd Assignment1_Attrition
jupyter notebook train.ipynb
streamlit run streamlit_app.py
```

### **Assignment 2**

```
cd Assignment2_Debugging
jupyter notebook fixed_pipeline.ipynb
```

### **Assignment 3**

```
cd Assignment3_Productivity
jupyter notebook productivity_feature_engineering.ipynb
```

---

# ğŸ”® **Tech Stack**

* **Python 3.10+**
* **scikit-learn**
* **XGBoost**
* **SHAP**
* **Pandas / Numpy**
* **Matplotlib / Seaborn**
* **Pipeline + ColumnTransformer**
* **Streamlit UI** (Assignment 1)

---

# ğŸ“ **What This Project Demonstrates**

### âœ” Core ML Development

* Feature engineering
* Pipeline design
* Model selection & evaluation
* Hyperparameter tuning

### âœ” ML Debugging & Anti-Patterns

* Detecting leakage
* Fixing flawed pipelines
* Validating cross-validation strategies

### âœ” Explainability & Interpretability

* SHAP values
* Feature-importance dashboards

### âœ” Deployment Readiness

* Reusable Pipelines
* Saved artifacts
* Prediction interfaces

---


